# PIPELINE ETL PARA BASE DA RECEITA FEDERAL - CNPJ

## ğŸ‘‹ ApresentaÃ§Ã£o
- Â  Este projeto visa criar uma pipeline de dados, otimizando o processo mensal de ExtraÃ§Ã£o, Limpeza e Carregamento **(ETL)** das bases referentes a CNPJ da Receita Federal, facilitando o dia a dia dos analistas do Departamento Interno de PrestaÃ§Ã£o de Contas (DIPC) da Controladoria do Estado de Pernambuco

## ğŸ—ï¸ Funcionamento
- Monitoramento e AtivaÃ§Ã£o AutomÃ¡tica
Â  Â  * A pipeline opera em modo "vigilante", verificando diariamente o site da Receita Federal pela publicaÃ§Ã£o dos dados do mÃªs de referÃªncia.
Â  Â  * O processo sÃ³ Ã© iniciado quando os novos arquivos sÃ£o detectados, evitando execuÃ§Ãµes desnecessÃ¡rias.

- Etapa 1: ExtraÃ§Ã£o
Â  Â  * Download: Baixa automaticamente todos os arquivos .zip do portal da Receita para uma pasta temporÃ¡ria.
Â  Â  * DescompactaÃ§Ã£o: Extrai o conteÃºdo dos arquivos .zip (arquivos .csv, .socios, .estabele, etc.).

- Etapa 2: TransformaÃ§Ã£o
Â  Â  * CorreÃ§Ã£o de Formato: Detecta o encoding original de cada arquivo e o converte para um padrÃ£o Ãºnico e moderno (UTF-8).
Â  Â  * RenomeaÃ§Ã£o: Salva os arquivos corrigidos com um sufixo (ex: __corrigido) em uma pasta de destino final, mantendo os arquivos originais intactos para referÃªncia.

- Etapa 3: ValidaÃ§Ã£o PÃ³s-TransformaÃ§Ã£o
Â  Â  * Contagem de Linhas: Compara a quantidade de linhas do arquivo original com a do arquivo corrigido para garantir que nenhum dado foi perdido durante a conversÃ£o. O processo Ã© abortado se houver divergÃªncia.
Â  Â  
- Etapa 4: Carga
Â  Â  * PreparaÃ§Ã£o do Banco de Dados: Conecta-se ao PostgreSQL e cria um schema especÃ­fico para o mÃªs e ano dos dados (ex: rfb_202509).
Â  Â  * Carga de Dados: Utiliza o comando COPY do PostgreSQL, a forma mais eficiente de carregar os milhÃµes de registros dos arquivos corrigidos para as tabelas correspondentes.

- Etapa 5: ValidaÃ§Ã£o PÃ³s-Carga
Â  Â  * VerificaÃ§Ã£o de Integridade: ApÃ³s a carga, executa uma sÃ©rie de testes SQL automÃ¡ticos na base de dados para confirmar: 
Â  Â  Â  Â  * A contagem de registros na tabela bate com a do arquivo.
Â  Â  Â  Â  * NÃ£o hÃ¡ deslocamento de colunas (checando valores nulos em colunas essenciais e formatos de dados).
Â  Â  * Em caso de falha, a operaÃ§Ã£o pode ser revertida (ROLLBACK) para nÃ£o manter dados inconsistentes no banco.

- NotificaÃ§Ã£o e FinalizaÃ§Ã£o
Â  Â  * Sucesso: Ao final do processo, envia uma notificaÃ§Ã£o (ex: por e-mail) informando que a carga foi concluÃ­da com sucesso e os dados estÃ£o prontos para uso.
Â  Â  * Falha: Se ocorrer qualquer erro em qualquer etapa, a pipeline para e envia um alerta detalhado, informando exatamente onde e por que a falha ocorreu.

---

## ğŸš€ Como Utilizar

### PrÃ©-requisitos
- Python 3.8 ou superior
- Acesso a um servidor PostgreSQL

### 1. InstalaÃ§Ã£o
Clone ou baixe este repositÃ³rio para a sua mÃ¡quina. Em seguida, abra um terminal na pasta raiz do projeto e siga os passos abaixo:

1.  **Crie o ambiente virtual:**
    ```bash
    python -m venv venv
    ```

2.  **Ative o ambiente virtual:**
    - No Windows (PowerShell): `.\venv\Scripts\Activate.ps1`
    - No Mac/Linux: `source venv/bin/activate`

3.  **Instale todas as dependÃªncias:**
    ```bash
    pip install -r requirements.txt
    ```

### 2. ConfiguraÃ§Ã£o
Antes de executar, vocÃª **precisa** adicionar suas informaÃ§Ãµes de conexÃ£o e o caminho da pasta de destino.

1.  Abra o arquivo: `src/config.py`
2.  Preencha as informaÃ§Ãµes solicitadas:
    - `PASTA_RAIZ_DESTINO`: O caminho da pasta principal onde os dados de cada mÃªs serÃ£o salvos (ex: `r"C:\Users\SeuNome\Desktop\DadosRFB"`).
    - `CONFIG_BD`: Preencha o dicionÃ¡rio com seu usuÃ¡rio, senha, host, porta e nome do banco de dados.

### 3. ExecuÃ§Ã£o
Com o ambiente virtual ativado e o arquivo `config.py` preenchido, execute o script principal com o seguinte comando:

```bash
python src/main.py