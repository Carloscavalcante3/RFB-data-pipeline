# PIPELINE ETL PARA BASE DA RECEITA FEDERAL - CNPJ

## üëã Apresenta√ß√£o
- ¬† Este projeto visa criar uma pipeline de dados, otimizando o processo mensal de Extra√ß√£o, Limpeza e Carregamento **(ETL)** das bases referentes a CNPJ da Receita Federal, facilitando o dia a dia dos analistas do Departamento Interno de Presta√ß√£o de Contas (DIPC) da Controladoria do Estado de Pernambuco

## üèóÔ∏è Funcionamento
- Monitoramento e Ativa√ß√£o Autom√°tica
    * A pipeline opera em modo "vigilante", verificando diariamente o site da Receita Federal pela publica√ß√£o dos dados do m√™s de refer√™ncia.
    * O processo s√≥ √© iniciado quando os novos arquivos s√£o detectados, evitando execu√ß√µes desnecess√°rias.

- Etapa 1: Extra√ß√£o
    * Download: Baixa automaticamente todos os arquivos .zip do portal da Receita para uma pasta tempor√°ria.
    * Descompacta√ß√£o: Extrai o conte√∫do dos arquivos .zip (arquivos .csv, .socios, .estabele, etc.).

- Etapa 2: Transforma√ß√£o
    * Corre√ß√£o de Formato: Detecta o encoding original de cada arquivo e o converte para um padr√£o √∫nico e moderno (UTF-8).
    * Renomea√ß√£o: Salva os arquivos corrigidos com um sufixo (ex: __corrigido) em uma pasta de destino final, mantendo os arquivos originais intactos para refer√™ncia.

- Etapa 3: Valida√ß√£o P√≥s-Transforma√ß√£o
    * Contagem de Linhas: Compara a quantidade de linhas do arquivo original com a do arquivo corrigido para garantir que nenhum dado foi perdido durante a convers√£o. O processo √© abortado se houver diverg√™ncia.
¬† ¬† 
- Etapa 4: Carga
    * Prepara√ß√£o do Banco de Dados: Conecta-se ao PostgreSQL e cria um schema espec√≠fico para o m√™s e ano dos dados (ex: rfb_202509).
    * Carga de Dados: Utiliza o comando COPY do PostgreSQL, a forma mais eficiente de carregar os milh√µes de registros dos arquivos corrigidos para as tabelas correspondentes.

- Etapa 5: Valida√ß√£o P√≥s-Carga
    * Verifica√ß√£o de Integridade: Ap√≥s a carga, executa uma s√©rie de testes SQL autom√°ticos na base de dados para confirmar: 
        * A contagem de registros na tabela bate com a do arquivo.
        * N√£o h√° deslocamento de colunas (checando valores nulos em colunas essenciais e formatos de dados).
    * Em caso de falha, a opera√ß√£o pode ser revertida (ROLLBACK) para n√£o manter dados inconsistentes no banco.

- Notifica√ß√£o e Finaliza√ß√£o
    * Sucesso: Ao final do processo, envia uma notifica√ß√£o (ex: por e-mail) informando que a carga foi conclu√≠da com sucesso e os dados est√£o prontos para uso.
    * Falha: Se ocorrer qualquer erro em qualquer etapa, a pipeline para e envia um alerta detalhado, informando exatamente onde e por que a falha ocorreu.

---

## üöÄ Como Utilizar

### Pr√©-requisitos
- Python 3.8 ou superior
- Acesso a um servidor PostgreSQL

### 1. Instala√ß√£o
Clone ou baixe este reposit√≥rio para a sua m√°quina. Em seguida, abra um terminal na pasta raiz do projeto e siga os passos abaixo:

1.  **Crie o ambiente virtual:**
    ```bash
    python -m venv venv
    ```

2.  **Ative o ambiente virtual:**
    - No Windows (PowerShell): `.\venv\Scripts\Activate.ps1`
    - No Mac/Linux: `source venv/bin/activate`

3.  **Instale todas as depend√™ncias:**
    ```bash
    pip install -r requirements.txt
    ```

### 2. Configura√ß√£o
Antes de executar, voc√™ **precisa** adicionar suas informa√ß√µes de conex√£o e o caminho da pasta de destino.

1.  Abra o arquivo: `src/config.py`
2.  Preencha as informa√ß√µes solicitadas:
    - `PASTA_RAIZ_DESTINO`: O caminho da pasta principal onde os dados de cada m√™s ser√£o salvos (ex: `r"C:\Users\SeuNome\Desktop\DadosRFB"`).
    - `CONFIG_BD`: Preencha o dicion√°rio com seu usu√°rio, senha, host, porta e nome do banco de dados.

### 3. Execu√ß√£o
Com o ambiente virtual ativado e o arquivo `config.py` preenchido, execute o script principal com o seguinte comando:

```bash
python src/main.py